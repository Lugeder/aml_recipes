{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import hstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Concatenate\n",
    "from keras.models import Sequential\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "from tensorflow_docs.vis import embed\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.getcwd()\n",
    "df = pd.read_csv(dir + r'\\data\\df_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:1000]\n",
    "df = df[['ingredients','label']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent_testdata = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_length_ex = 1024\n",
    "# train_data_ex = torch.zeros((train_data_length_ex, 2))\n",
    "# train_data_ex[:, 0] = 2 * math.pi * torch.rand(train_data_length_ex)\n",
    "# train_data_ex[:, 1] = torch.sin(train_data_ex[:, 0])\n",
    "# train_labels_ex = torch.zeros(train_data_length_ex)\n",
    "# train_set_ex = [\n",
    "#     (train_data_ex[i], train_labels_ex[i]) for i in range(train_data_length_ex)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_ex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform column \"ingredients\" to list \n",
    "df = df.assign(ingredients = [ast.literal_eval(x) for x in df.ingredients])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all words in ingredients which include numbers\n",
    "df = df.assign(ingredients = [[(''.join([x + ' ' for x in x_sent.split() if not bool(re.search(r'\\d', x))]).strip()) for x_sent in x_list] for x_list in df.ingredients])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordEnc = OrdinalEncoder()\n",
    "# ohEnc = OneHotEncoder()\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(\n",
    "    pd.DataFrame.sparse.from_spmatrix(\n",
    "        mlb.fit_transform(df.pop('ingredients')),\n",
    "        index = df.index, \n",
    "        columns = mlb.classes_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join columns with similar names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th>accent seasoning</th>\n",
       "      <th>acorn squash</th>\n",
       "      <th>active dry yeast</th>\n",
       "      <th>adobo sauce</th>\n",
       "      <th>adobo seasoning</th>\n",
       "      <th>agave nectar</th>\n",
       "      <th>alfredo sauce</th>\n",
       "      <th>all-bran cereal</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow cornmeal</th>\n",
       "      <th>yellow mustard</th>\n",
       "      <th>yellow onion</th>\n",
       "      <th>yellow onions</th>\n",
       "      <th>yellow pepper</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yukon gold potatoes</th>\n",
       "      <th>zest of</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label     accent seasoning  acorn squash  active dry yeast  adobo sauce  \\\n",
       "0        2  0                 0             0                 0            0   \n",
       "1        0  0                 0             0                 0            0   \n",
       "2        2  0                 0             0                 0            0   \n",
       "3        2  0                 0             0                 0            0   \n",
       "4        2  0                 0             0                 0            0   \n",
       "..     ... ..               ...           ...               ...          ...   \n",
       "995      2  0                 0             0                 0            0   \n",
       "996      2  0                 0             0                 0            0   \n",
       "997      2  0                 0             0                 0            0   \n",
       "998      2  0                 0             0                 0            0   \n",
       "999      2  0                 0             0                 0            0   \n",
       "\n",
       "     adobo seasoning  agave nectar  alfredo sauce  all-bran cereal  ...  \\\n",
       "0                  0             0              0                0  ...   \n",
       "1                  0             0              0                0  ...   \n",
       "2                  0             0              0                0  ...   \n",
       "3                  0             0              0                0  ...   \n",
       "4                  0             0              0                0  ...   \n",
       "..               ...           ...            ...              ...  ...   \n",
       "995                0             0              0                0  ...   \n",
       "996                0             0              0                0  ...   \n",
       "997                0             0              0                0  ...   \n",
       "998                0             0              0                0  ...   \n",
       "999                0             0              0                0  ...   \n",
       "\n",
       "     yellow cornmeal  yellow mustard  yellow onion  yellow onions  \\\n",
       "0                  0               0             0              0   \n",
       "1                  0               0             0              0   \n",
       "2                  0               0             0              0   \n",
       "3                  0               0             0              0   \n",
       "4                  0               0             0              0   \n",
       "..               ...             ...           ...            ...   \n",
       "995                0               0             0              0   \n",
       "996                0               0             0              0   \n",
       "997                0               0             0              0   \n",
       "998                0               0             0              0   \n",
       "999                0               0             0              0   \n",
       "\n",
       "     yellow pepper  yellow squash  yogurt  yukon gold potatoes  zest of  \\\n",
       "0                0              0       0                    0        0   \n",
       "1                0              0       0                    0        0   \n",
       "2                0              0       0                    0        0   \n",
       "3                0              0       0                    0        0   \n",
       "4                0              0       0                    0        0   \n",
       "..             ...            ...     ...                  ...      ...   \n",
       "995              0              0       0                    0        0   \n",
       "996              0              0       0                    0        0   \n",
       "997              0              0       0                    0        0   \n",
       "998              0              0       0                    0        0   \n",
       "999              0              0       0                    0        0   \n",
       "\n",
       "     zucchini  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "..        ...  \n",
       "995         0  \n",
       "996         0  \n",
       "997         0  \n",
       "998         0  \n",
       "999         0  \n",
       "\n",
       "[1000 rows x 1982 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if two column names have a similarity of more than 90%, they are merged\n",
    "ingredients = []\n",
    "for column in df.columns:\n",
    "    # print('\\n', column)\n",
    "    if any(SequenceMatcher(None, ing, column).ratio() > 0.9 for ing in ingredients):\n",
    "        # print('dublette')\n",
    "        for ing in ingredients:\n",
    "            if SequenceMatcher(None, ing, column).ratio() > 0.9:\n",
    "                df.rename({column: ing}, axis=1, inplace = True) \n",
    "                # print(column, ing)\n",
    "    else:\n",
    "        # print('no dublette')\n",
    "        ingredients.append(column)\n",
    "        # print(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accent seasoning</th>\n",
       "      <th>acorn squash</th>\n",
       "      <th>active dry yeast</th>\n",
       "      <th>adobo sauce</th>\n",
       "      <th>adobo seasoning</th>\n",
       "      <th>agave nectar</th>\n",
       "      <th>alfredo sauce</th>\n",
       "      <th>all-bran cereal</th>\n",
       "      <th>all-purpose flour</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow cake mix</th>\n",
       "      <th>yellow cornmeal</th>\n",
       "      <th>yellow mustard</th>\n",
       "      <th>yellow onion</th>\n",
       "      <th>yellow pepper</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yukon gold potatoes</th>\n",
       "      <th>zest of</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1860 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        accent seasoning  acorn squash  active dry yeast  adobo sauce  \\\n",
       "0    0                 0             0                 0            0   \n",
       "1    0                 0             0                 0            0   \n",
       "2    0                 0             0                 0            0   \n",
       "3    0                 0             0                 0            0   \n",
       "4    0                 0             0                 0            0   \n",
       "..  ..               ...           ...               ...          ...   \n",
       "995  0                 0             0                 0            0   \n",
       "996  0                 0             0                 0            0   \n",
       "997  0                 0             0                 0            0   \n",
       "998  0                 0             0                 0            0   \n",
       "999  0                 0             0                 0            0   \n",
       "\n",
       "     adobo seasoning  agave nectar  alfredo sauce  all-bran cereal  \\\n",
       "0                  0             0              0                0   \n",
       "1                  0             0              0                0   \n",
       "2                  0             0              0                0   \n",
       "3                  0             0              0                0   \n",
       "4                  0             0              0                0   \n",
       "..               ...           ...            ...              ...   \n",
       "995                0             0              0                0   \n",
       "996                0             0              0                0   \n",
       "997                0             0              0                0   \n",
       "998                0             0              0                0   \n",
       "999                0             0              0                0   \n",
       "\n",
       "     all-purpose flour  ...  yellow cake mix  yellow cornmeal  yellow mustard  \\\n",
       "0                    0  ...                0                0               0   \n",
       "1                    0  ...                0                0               0   \n",
       "2                    0  ...                0                0               0   \n",
       "3                    0  ...                0                0               0   \n",
       "4                    0  ...                0                0               0   \n",
       "..                 ...  ...              ...              ...             ...   \n",
       "995                  0  ...                0                0               0   \n",
       "996                  0  ...                0                0               0   \n",
       "997                  0  ...                0                0               0   \n",
       "998                  0  ...                0                0               0   \n",
       "999                  0  ...                0                0               0   \n",
       "\n",
       "     yellow onion  yellow pepper  yellow squash  yogurt  yukon gold potatoes  \\\n",
       "0               0              0              0       0                    0   \n",
       "1               0              0              0       0                    0   \n",
       "2               0              0              0       0                    0   \n",
       "3               0              0              0       0                    0   \n",
       "4               0              0              0       0                    0   \n",
       "..            ...            ...            ...     ...                  ...   \n",
       "995             0              0              0       0                    0   \n",
       "996             0              0              0       0                    0   \n",
       "997             0              0              0       0                    0   \n",
       "998             0              0              0       0                    0   \n",
       "999             0              0              0       0                    0   \n",
       "\n",
       "     zest of  zucchini  \n",
       "0          0         0  \n",
       "1          0         0  \n",
       "2          0         0  \n",
       "3          0         0  \n",
       "4          0         0  \n",
       "..       ...       ...  \n",
       "995        0         0  \n",
       "996        0         0  \n",
       "997        0         0  \n",
       "998        0         0  \n",
       "999        0         0  \n",
       "\n",
       "[1000 rows x 1860 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge columns with same name\n",
    "df.groupby(level = 0, axis = 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe column names for caro weil sie es manuell bearbeiten will :D \n",
    "\n",
    "file = open(dir + r'\\data\\an_caro.csv','w')\n",
    "for item in list(df.columns):\n",
    "\tfile.write(item+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversion to PyTorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_tensor = torch.tensor(df['alfredo sauce'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversion to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df[list(df.columns)[2:]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train test split\n",
    "# trainy, testy = model_selection.train_test_split(y, test_size = 0.2, random_state= 42, shuffle = True)\n",
    "# trainX, testX = model_selection.train_test_split(X, test_size = 0.2, random_state= 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example of loading the fashion_mnist dataset\n",
    "# from keras.datasets.fashion_mnist import load_data\n",
    "# # load the recipes into memory\n",
    "# (trainX, trainy), (testX, testy) = load_data()\n",
    "# # summarize the shape of the dataset\n",
    "# print('Train', trainX.shape, trainy.shape)\n",
    "# print('Test', testX.shape, testy.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional GAN\n",
    "<!-- source of following section: https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/ -->\n",
    "following section based on: https://keras.io/examples/generative/conditional_gan/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_channels = 1\n",
    "num_classes = 3\n",
    "feature_size = len(df.columns) - 2\n",
    "latent_dim = 300"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## special preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df['label']\n",
    "df_features = df.drop(df.columns[[0,1]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of labels\n",
    "df_labels = keras.utils.to_categorical(df_labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert features dataframe to numpy array\n",
    "df_features = pd.DataFrame(df_features).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = (\n",
    "#     tf.data.Dataset.from_tensor_slices(\n",
    "#         (        \n",
    "#             tf.cast(df_features.values, tf.float32),\n",
    "#             tf.cast(df_labels.values, tf.int32)\n",
    "#         )\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tensor = (tf.convert_to_tensor(df_features))\n",
    "label_tensor = (tf.convert_to_tensor(df_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = feature_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_false = tf.data.Dataset.from_tensor_slices((df_features, df_labels))\n",
    "# dataset_false = dataset_false.shuffle(buffer_size = 1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for features_tensor, target_tensor in dataset:\n",
    "#     if count == 0:\n",
    "#         print(f'features:{features_tensor} target:{target_tensor}')\n",
    "#     count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((df_features, df_labels))\n",
    "dataset = dataset.shuffle(buffer_size = 1024).batch(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# all_digits = np.concatenate([x_train, x_test])\n",
    "# all_labels = np.concatenate([y_train, y_test])\n",
    "\n",
    "# # Scale the pixel values to [0, 1] range, add a channel dimension to\n",
    "# # the recipes, and one-hot encode the labels.\n",
    "# all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "# all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "# all_labels = keras.utils.to_categorical(all_labels, 10)\n",
    "\n",
    "# # Create tf.data.Dataset.\n",
    "# test = tf.data.Dataset.from_tensor_slices((all_digits, all_labels))\n",
    "# test = test.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(all_digits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculating numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 4\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((df_features.shape[1], 1, discriminator_in_channels)),\n",
    "        layers.Conv2D(df_features.shape[1]*2, (3,3), strides = (2, 2), padding = 'same'),\n",
    "        layers.LeakyReLU(alpha = 0.2),\n",
    "        layers.Conv2D(df_features.shape[1]*4, (3,3), strides = (2, 2), padding = 'same'),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ], \n",
    "    name = 'discriminator'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the generator.\n",
    "# generator = keras.Sequential(\n",
    "#     [\n",
    "#         keras.layers.InputLayer((generator_in_channels,)),\n",
    "#         # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "#         # 7x7x(128 + num_classes) map.\n",
    "        # layers.Dense(7 * 7 * generator_in_channels), # 7*7+138 = 6762\n",
    "#         layers.LeakyReLU(alpha=0.2),\n",
    "#         layers.Reshape((7, 7, generator_in_channels)), # 7,7,138\n",
    "#         layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"), # 7,7,138\n",
    "#         layers.LeakyReLU(alpha=0.2),\n",
    "#         layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"), # 7,7,138\n",
    "#         layers.LeakyReLU(alpha=0.2),\n",
    "#         layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"), #\n",
    "#     ],\n",
    "#     name=\"generator\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "        # 7x7x(128 + num_classes) map.\n",
    "        layers.Dense(7 * generator_in_channels),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((7, generator_in_channels)),\n",
    "        layers.Conv1DTranspose(128, 10, strides=2, padding=\"valid\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv1DTranspose(128, 12, strides=2, padding=\"valid\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv1DTranspose(128, 10, strides=2, padding=\"valid\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv1DTranspose(128, 10, strides=2, padding=\"valid\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv1DTranspose(128, 12, strides=2, padding=\"valid\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv1DTranspose(128, 12, strides=2, padding=\"valid\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv1DTranspose(128, 12, strides=2, padding=\"valid\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv1D(1, 11, padding=\"valid\", activation=\"sigmoid\"),\n",
    "        # layers.LeakyReLU(alpha=0.2),\n",
    "        # layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_recipes, one_hot_labels = data\n",
    "        print(real_recipes)\n",
    "        real_recipes = tf.cast(real_recipes, tf.float32)\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the recipes. This is for the discriminator.\n",
    "        recipe_one_hot_labels = one_hot_labels[:, :, None]\n",
    "        recipe_one_hot_labels = tf.repeat(\n",
    "            recipe_one_hot_labels, repeats=[feature_size]\n",
    "        )\n",
    "        recipe_one_hot_labels = tf.reshape(\n",
    "            recipe_one_hot_labels, (-1, feature_size, num_classes)\n",
    "        )\n",
    "        # print(recipe_one_hot_labels)\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_recipes)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "        \n",
    "        # Decode the noise (guided by labels) to fake recipes.\n",
    "        generated_recipes = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real recipes. Note that we are concatenating the labels\n",
    "        # with these recipes here.\n",
    "        fake_recipe_and_labels = tf.concat([generated_recipes, recipe_one_hot_labels], -1)\n",
    "        print(real_recipes)\n",
    "        print(recipe_one_hot_labels)\n",
    "        real_recipe_and_labels = tf.concat([real_recipes, recipe_one_hot_labels], -1)\n",
    "        combined_recipes = tf.concat(\n",
    "            [fake_recipe_and_labels, real_recipe_and_labels], axis=0\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Assemble labels discriminating real from fake recipes.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        \n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_recipes)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real recipes\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_recipes = self.generator(random_vector_labels)\n",
    "            fake_recipe_and_labels = tf.concat([fake_recipes, recipe_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_recipe_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Tensor(\"IteratorGetNext:0\", shape=(None, 1980), dtype=int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\I539063\\Documents\\venvs\\DHBW_Semester_6\\AML_Scherer\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\I539063\\Documents\\venvs\\DHBW_Semester_6\\AML_Scherer\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\I539063\\Documents\\venvs\\DHBW_Semester_6\\AML_Scherer\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\I539063\\AppData\\Local\\Temp\\ipykernel_28096\\2059624283.py\", line 24, in train_step\n        real_recipes = real_recipes[:, :, 1]\n\n    ValueError: Index out of range using input dim 2; input has only 2 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=3, ellipsis_mask=0, end_mask=3, new_axis_mask=0, shrink_axis_mask=4](IteratorGetNext, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [?,1980], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[393], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m cond_gan \u001b[39m=\u001b[39m ConditionalGAN(\n\u001b[0;32m      2\u001b[0m     discriminator\u001b[39m=\u001b[39mdiscriminator, generator\u001b[39m=\u001b[39mgenerator, latent_dim\u001b[39m=\u001b[39mlatent_dim\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m cond_gan\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      5\u001b[0m     d_optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.0003\u001b[39m),\n\u001b[0;32m      6\u001b[0m     g_optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.0003\u001b[39m),\n\u001b[0;32m      7\u001b[0m     loss_fn\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m cond_gan\u001b[39m.\u001b[39;49mfit(dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\I539063\\Documents\\venvs\\DHBW_Semester_6\\AML_Scherer\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filetww7lz1e.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[392], line 24\u001b[0m, in \u001b[0;36mConditionalGAN.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     22\u001b[0m real_recipes, one_hot_labels \u001b[39m=\u001b[39m data\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(real_recipes)\n\u001b[1;32m---> 24\u001b[0m real_recipes \u001b[39m=\u001b[39m real_recipes[:, :, \u001b[39m1\u001b[39;49m]\n\u001b[0;32m     25\u001b[0m \u001b[39mprint\u001b[39m(real_recipes)\n\u001b[0;32m     26\u001b[0m real_recipes \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(real_recipes, tf\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\I539063\\Documents\\venvs\\DHBW_Semester_6\\AML_Scherer\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\I539063\\Documents\\venvs\\DHBW_Semester_6\\AML_Scherer\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\I539063\\Documents\\venvs\\DHBW_Semester_6\\AML_Scherer\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\I539063\\AppData\\Local\\Temp\\ipykernel_28096\\2059624283.py\", line 24, in train_step\n        real_recipes = real_recipes[:, :, 1]\n\n    ValueError: Index out of range using input dim 2; input has only 2 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=3, ellipsis_mask=0, end_mask=3, new_axis_mask=0, shrink_axis_mask=4](IteratorGetNext, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [?,1980], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n"
     ]
    }
   ],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "cond_gan.fit(dataset, epochs=15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 1980), dtype=tf.int32, name=None), TensorSpec(shape=(None, 3), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolating between classes with the trained generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[160], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m start_class \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# @param {type:\"slider\", min:0, max:9, step:1}\u001b[39;00m\n\u001b[0;32m     35\u001b[0m end_class \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m  \u001b[39m# @param {type:\"slider\", min:0, max:9, step:1}\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m fake_images \u001b[39m=\u001b[39m interpolate_class(start_class, end_class)\n",
      "Cell \u001b[1;32mIn[160], line 17\u001b[0m, in \u001b[0;36minterpolate_class\u001b[1;34m(first_number, second_number)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minterpolate_class\u001b[39m(first_number, second_number):\n\u001b[0;32m     15\u001b[0m     \u001b[39m# Convert the start and end labels to one-hot encoded vectors.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     first_label \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_categorical([first_number], num_classes)\n\u001b[1;32m---> 17\u001b[0m     second_label \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mto_categorical([second_number], num_classes)\n\u001b[0;32m     18\u001b[0m     first_label \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(first_label, tf\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     19\u001b[0m     second_label \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(second_label, tf\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Users\\I539063\\Documents\\venvs\\DHBW_Semester_6\\AML_Scherer\\lib\\site-packages\\keras\\utils\\np_utils.py:74\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     72\u001b[0m n \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m     73\u001b[0m categorical \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n, num_classes), dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m---> 74\u001b[0m categorical[np\u001b[39m.\u001b[39;49marange(n), y] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     75\u001b[0m output_shape \u001b[39m=\u001b[39m input_shape \u001b[39m+\u001b[39m (num_classes,)\n\u001b[0;32m     76\u001b[0m categorical \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(categorical, output_shape)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "# We first extract the trained generator from our Conditional GAN.\n",
    "trained_gen = cond_gan.generator\n",
    "\n",
    "# Choose the number of intermediate recipes that would be generated in\n",
    "# between the interpolation + 2 (start and last recipes).\n",
    "num_interpolation = 9  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n",
    "interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
    "\n",
    "\n",
    "def interpolate_class(first_number, second_number):\n",
    "    # Convert the start and end labels to one-hot encoded vectors.\n",
    "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "    first_label = tf.cast(first_label, tf.float32)\n",
    "    second_label = tf.cast(second_label, tf.float32)\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n",
    "    percent_second_label = tf.cast(percent_second_label, tf.float32)\n",
    "    interpolation_labels = (\n",
    "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    )\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n",
    "\n",
    "start_class = 1  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "end_class = 5  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "\n",
    "fake_recipes = interpolate_class(start_class, end_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_recipes *= 255.0\n",
    "converted_recipes = fake_recipes.astype(np.uint8)\n",
    "converted_recipes = tf.image.resize(converted_recipes, (96, 96)).numpy().astype(np.uint8)\n",
    "imageio.mimsave(\"animation.gif\", converted_recipes, fps=1)\n",
    "embed.embed_file(\"animation.gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML_Scherer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
