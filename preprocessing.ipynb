{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explanation of dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels: \n",
    "<br> 0: vegan\n",
    "<br> 1: vegetarian\n",
    "<br> 2: classic (neither vegetarian nor vegan label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set category of considered categories \n",
    "considered_categories = [0, 1, 2] # can be: [0,1,2] = ['vegan', 'vegetarian', 'classic']\n",
    "\n",
    "# set number of considered recipes \n",
    "number_of_recipes = None # if whole dataset is to be used insert None\n",
    "samples_per_class = 2000 # if max number of samples insert None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "import re\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read source data\n",
    "dir = os.getcwd()\n",
    "df = pd.read_csv(dir + r'\\data\\recipes_w_search_terms.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels by search terms in dataset\n",
    "df = df.assign(label=[0 if 'vegan' in x else 1 if 'vegetarian' in x else 2 for x in df.search_terms])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## safe labelled dataset to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(dir + r'\\data\\recipes_w_search_terms_labelled.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shorten and filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten dataset by manual max leng\n",
    "if  number_of_recipes != None:\n",
    "    df = df[:number_of_recipes]\n",
    "\n",
    "# filter for necessary columns\n",
    "df = df[['ingredients','label']]\n",
    "\n",
    "# filter labels (if not all categories shall be included)\n",
    "df = df[df.label.isin(considered_categories)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval distribution of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create seperated dataframes of different classes\n",
    "vegan_df = df[df.label == 0]\n",
    "vegetarian_df = df[df.label == 1]\n",
    "classic_df = df[df.label == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if manual number of samples per class inserted. If not, use min number of samples per class \n",
    "if samples_per_class == None:\n",
    "    samples_per_class = min_samples = min(vegan_df.shape[0], vegetarian_df.shape[0], classic_df.shape[0])\n",
    "\n",
    "# shuffle dataset and use n numbers per class\n",
    "vegan_df = vegan_df.sample(frac = 1)[0:samples_per_class]\n",
    "vegetarian_df = vegetarian_df.sample(frac = 1)[0:samples_per_class]\n",
    "classic_df = classic_df.sample(frac = 1)[0:samples_per_class]\n",
    "\n",
    "# concatenate dataframes \n",
    "df = pd.concat([vegan_df, vegetarian_df, classic_df], ignore_index = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess ingredients names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform column \"ingredients\" to list \n",
    "df = df.assign(ingredients = [ast.literal_eval(x) for x in df.ingredients])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all words in ingredients which include numbers\n",
    "df = df.assign(ingredients = [[(''.join([x + ' ' for x in x_sent.split() if not bool(re.search(r'\\d', x))]).strip()) for x_sent in x_list] for x_list in df.ingredients])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one hot encoding and split labels and features\n",
    "if no split --> risk of error: column 'labels' can be deleted while merging columns with similar names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding FEATURES\n",
    "# load MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "\n",
    "# execute one hot encoding\n",
    "df = df.join(\n",
    "    pd.DataFrame.sparse.from_spmatrix(\n",
    "        mlb.fit_transform(df.pop('ingredients')),\n",
    "        index = df.index, \n",
    "        columns = mlb.classes_\n",
    "    )\n",
    ")\n",
    "\n",
    "# drop labels to get features dataframe\n",
    "df_features = df.drop(df.columns[[0]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels dataframe\n",
    "df_labels = df['label']\n",
    "\n",
    "# one hot encoding LABELS\n",
    "df_labels = pd.get_dummies(df_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge columns with similar names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.columns[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe number of features before merging\n",
    "before_merge = len(df_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if two column names have a similarity of more than 90%, they are renamed the same\n",
    "similar_names = {}\n",
    "ingredients = []\n",
    "old_ingredients = [] # add ingredients one after another to this list so that new ingredients are only compared to those for runtime optimization\n",
    "for column in df_features.columns:\n",
    "    # if any(SequenceMatcher(None, ing, column).ratio() > 0.9 for ing in old_ingredients):\n",
    "    for ing in old_ingredients:\n",
    "        if SequenceMatcher(None, ing, column).ratio() > 0.9:\n",
    "            df_features.rename({column: ing}, axis=1, inplace = True) \n",
    "            similar_names[column] = ing\n",
    "    else:\n",
    "        ingredients.append(column)\n",
    "    old_ingredients.append(column)\n",
    "        \n",
    "# merge columns with same name\n",
    "df_features = df_features.groupby(level = 0, axis = 1).sum()\n",
    "\n",
    "# print similar names\n",
    "similar_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of features before merge:', before_merge, '\\nnumber of features after merge: ', len(df_features.columns))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# safe preprocessed df to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.to_csv(dir + r'\\data\\df_features.csv', index = False)\n",
    "df_labels.to_csv(dir + r'\\data\\df_labels.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML_Scherer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
